\chapter{Conclusions}
The main aim of this dissertation was to study the state-of-the-art techniques in speaker diarization and create a Kaldi-based system for the DIHARD II challenge. A detailed overview of the diarization process was presented that talked about some of the past and recent techniques used in the field. The motivation behind the DIHARD challenge and the evaluation rules were discussed. The working of the diarization baseline provided by the organizers of the challenge was discussed in detail. A brief overview of the Kaldi toolkit was also provided.

Several difficulties were faced during the dissertation. The first difficulty was getting the DIHARD 2019 datasets. When the topic for this dissertation was finalized, the DIHARD registration deadline had already passed. Thus, access to the 2019 datasets was denied. Luckily, the organizers made the 2018 development set available from LDC in June. This made it possible to run the systems by slightly modifying the file structure of the dataset. But the actual performance were not seen until the evaluation set was released, which was in the next month in July. This caused a significant delay in the dissertation. Another big problem was making the i-vector extractor training work on the university grid. A lot of time was spent to realize that memory was a bottleneck on the systems with 60 GB memory, which led to thrashing and slowing down the training which was already extremely slow. It was fixed by forcing the recipe to run on the only two systems which had 250 GB of memory. Another problem was compiling Kaldi with GPU, without which the x-vector DNN training was extremely slow. Other general problems included navigating through unfamiliar shell script code, getting the DIHARD baseline to work on the grid, fixing Kaldi errors, and writing some Kaldi C++ code to create a new program.

The system was created using the 2018 DIHARD datasets because the 2019 datasets were not available for use. The main aim was achieved and the best diarization system consisted of training a PLDA backend using concatenated i-vectors and x-vectors extracted from a combination of the VoxCeleb I dataset and the DIHARD development set. This achieved a performance of 24.64\% DER on the DIHARD evaluation set which  surpassed the baseline performance by a 7.3\% relative and 2\% absolute improvement and a 2\%. Looking at the systems from last year's challenge, this system is placed 4th. Some other experiments included training i-vector and x-vector extractors using scripts already present in Kaldi. This dissertation was a rewarding experience because it gave the opportunity to get familiar with recent advancements in the diarization field and implementing them, gaining a good amount of experience with Kaldi and getting to know people in the speech research community.
